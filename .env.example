# LLM Configuration
LLM_PROVIDER=openai
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Ollama Configuration (if using local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Vector Database Configuration
VECTOR_DB=chroma
CHROMA_PERSIST_DIR=./chroma_db

# Pinecone Configuration (if using Pinecone)
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment_here
PINECONE_INDEX_NAME=babyagi-tasks

# Task Configuration
MAX_ITERATIONS=5
OBJECTIVE=Develop a task list

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=babyagi.log

# API Configuration
API_HOST=0.0.0.0
API_PORT=5000
API_DEBUG=true

# Web Interface Configuration
WEB_HOST=0.0.0.0
WEB_PORT=7860

# Redis Configuration (for task queue)
REDIS_URL=redis://localhost:6379/0